{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Final - Processamento de Linguagem Natural\n",
    "\n",
    "Aplicação de Técnicas de PLN para Detecção de Plágio em Documentos\n",
    "\n",
    "Baseado no artigo \"Using Natural Language Processing for Automatic Detection of Plagiarism\"\n",
    "\n",
    "Alunos: Renan Baisso 11064215, Yago Sorrilha 11047514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\renan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\renan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_segmentation (string):\n",
    "    segmented_string = nltk.sent_tokenize(string)\n",
    "    return segmented_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_without_punct(string):\n",
    "    regex_punctuation = r'[^\\w\\s]'\n",
    "    string_without_punct = re.sub(regex_punctuation,'',string)\n",
    "    return string_without_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.VERB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    \n",
    "    for w in words:\n",
    "        lemmas.append(lemmatizer.lemmatize(w, get_wordnet_pos(w)))\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(string):\n",
    "    #https://www.w3schools.com/python/python_regex.asp#findall\n",
    "    regex = r\"\\b[-a-zA-ZÀ-ÖØ-öø-ÿ0-9]+\\b\"\n",
    "    return re.findall(regex, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(word):\n",
    "    return [ w.lower() for w in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PorterStemmerCustom:\n",
    "    #https://tartarus.org/martin/PorterStemmer/python.txt\n",
    "    def isCons(self, letter):\n",
    "        if letter == 'a' or letter == 'e' or letter == 'i' or letter == 'o' or letter == 'u':\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def isConsonant(self, word, i):\n",
    "        letter = word[i]\n",
    "        if self.isCons(letter):\n",
    "            if letter == 'y' and self.isCons(word[i-1]):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def isVowel(self, word, i):\n",
    "        return not(self.isConsonant(word, i))\n",
    "\n",
    "    # *S\n",
    "    def endsWith(self, stem, letter):\n",
    "        if stem.endswith(letter):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # *v*\n",
    "    def containsVowel(self, stem):\n",
    "        for i in stem:\n",
    "            if not self.isCons(i):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # *d\n",
    "    def doubleCons(self, stem):\n",
    "        if len(stem) >= 2:\n",
    "            if self.isConsonant(stem, -1) and self.isConsonant(stem, -2):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def getForm(self, word):\n",
    "        form = []\n",
    "        formStr = ''\n",
    "        for i in range(len(word)):\n",
    "            if self.isConsonant(word, i):\n",
    "                if i != 0:\n",
    "                    prev = form[-1]\n",
    "                    if prev != 'C':\n",
    "                        form.append('C')\n",
    "                else:\n",
    "                    form.append('C')\n",
    "            else:\n",
    "                if i != 0:\n",
    "                    prev = form[-1]\n",
    "                    if prev != 'V':\n",
    "                        form.append('V')\n",
    "                else:\n",
    "                    form.append('V')\n",
    "        for j in form:\n",
    "            formStr += j\n",
    "        return formStr\n",
    "\n",
    "    def getM(self, word):\n",
    "        form = self.getForm(word)\n",
    "        m = form.count('VC')\n",
    "        return m\n",
    "\n",
    "    # *o\n",
    "    def cvc(self, word):\n",
    "        if len(word) >= 3:\n",
    "            f = -3\n",
    "            s = -2\n",
    "            t = -1\n",
    "            third = word[t]\n",
    "            if self.isConsonant(word, f) and self.isVowel(word, s) and self.isConsonant(word, t):\n",
    "                if third != 'w' and third != 'x' and third != 'y':\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def replace(self, orig, rem, rep):\n",
    "        result = orig.rfind(rem)\n",
    "        base = orig[:result]\n",
    "        replaced = base + rep\n",
    "        return replaced\n",
    "\n",
    "    def replaceM0(self, orig, rem, rep):\n",
    "        result = orig.rfind(rem)\n",
    "        base = orig[:result]\n",
    "        if self.getM(base) > 0:\n",
    "            replaced = base + rep\n",
    "            return replaced\n",
    "        else:\n",
    "            return orig\n",
    "\n",
    "    def replaceM1(self, orig, rem, rep):\n",
    "        result = orig.rfind(rem)\n",
    "        base = orig[:result]\n",
    "        if self.getM(base) > 1:\n",
    "            replaced = base + rep\n",
    "            return replaced\n",
    "        else:\n",
    "            return orig\n",
    "\n",
    "    def step1a(self, word):\n",
    "        if word.endswith('sses'):\n",
    "            word = self.replace(word, 'sses', 'ss')\n",
    "        elif word.endswith('ies'):\n",
    "            word = self.replace(word, 'ies', 'i')\n",
    "        elif word.endswith('ss'):\n",
    "            word = self.replace(word, 'ss', 'ss')\n",
    "        elif word.endswith('s'):\n",
    "            word = self.replace(word, 's', '')\n",
    "        else:\n",
    "            pass\n",
    "        return word\n",
    "\n",
    "    def step1b(self, word):\n",
    "        flag = False\n",
    "        if word.endswith('eed'):\n",
    "            result = word.rfind('eed')\n",
    "            base = word[:result]\n",
    "            if self.getM(base) > 0:\n",
    "                word = base\n",
    "                word += 'ee'\n",
    "        elif word.endswith('ed'):\n",
    "            result = word.rfind('ed')\n",
    "            base = word[:result]\n",
    "            if self.containsVowel(base):\n",
    "                word = base\n",
    "                flag = True\n",
    "        elif word.endswith('ing'):\n",
    "            result = word.rfind('ing')\n",
    "            base = word[:result]\n",
    "            if self.containsVowel(base):\n",
    "                word = base\n",
    "                flag = True\n",
    "        if flag:\n",
    "            if word.endswith('at') or word.endswith('bl') or word.endswith('iz'):\n",
    "                word += 'e'\n",
    "            elif self.doubleCons(word) and not self.endsWith(word, 'l') and not self.endsWith(word, 's') and not self.endsWith(word, 'z'):\n",
    "                word = word[:-1]\n",
    "            elif self.getM(word) == 1 and self.cvc(word):\n",
    "                word += 'e'\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        return word\n",
    "\n",
    "    def step1c(self, word):\n",
    "        if word.endswith('y'):\n",
    "            result = word.rfind('y')\n",
    "            base = word[:result]\n",
    "            if self.containsVowel(base):\n",
    "                word = base\n",
    "                word += 'i'\n",
    "        return word\n",
    "\n",
    "    def step2(self, word):\n",
    "        if word.endswith('ational'):\n",
    "            word = self.replaceM0(word, 'ational', 'ate')\n",
    "        elif word.endswith('tional'):\n",
    "            word = self.replaceM0(word, 'tional', 'tion')\n",
    "        elif word.endswith('enci'):\n",
    "            word = self.replaceM0(word, 'enci', 'ence')\n",
    "        elif word.endswith('anci'):\n",
    "            word = self.replaceM0(word, 'anci', 'ance')\n",
    "        elif word.endswith('izer'):\n",
    "            word = self.replaceM0(word, 'izer', 'ize')\n",
    "        elif word.endswith('abli'):\n",
    "            word = self.replaceM0(word, 'abli', 'able')\n",
    "        elif word.endswith('alli'):\n",
    "            word = self.replaceM0(word, 'alli', 'al')\n",
    "        elif word.endswith('entli'):\n",
    "            word = self.replaceM0(word, 'entli', 'ent')\n",
    "        elif word.endswith('eli'):\n",
    "            word = self.replaceM0(word, 'eli', 'e')\n",
    "        elif word.endswith('ousli'):\n",
    "            word = self.replaceM0(word, 'ousli', 'ous')\n",
    "        elif word.endswith('ization'):\n",
    "            word = self.replaceM0(word, 'ization', 'ize')\n",
    "        elif word.endswith('ation'):\n",
    "            word = self.replaceM0(word, 'ation', 'ate')\n",
    "        elif word.endswith('ator'):\n",
    "            word = self.replaceM0(word, 'ator', 'ate')\n",
    "        elif word.endswith('alism'):\n",
    "            word = self.replaceM0(word, 'alism', 'al')\n",
    "        elif word.endswith('iveness'):\n",
    "            word = self.replaceM0(word, 'iveness', 'ive')\n",
    "        elif word.endswith('fulness'):\n",
    "            word = self.replaceM0(word, 'fulness', 'ful')\n",
    "        elif word.endswith('ousness'):\n",
    "            word = self.replaceM0(word, 'ousness', 'ous')\n",
    "        elif word.endswith('aliti'):\n",
    "            word = self.replaceM0(word, 'aliti', 'al')\n",
    "        elif word.endswith('iviti'):\n",
    "            word = self.replaceM0(word, 'iviti', 'ive')\n",
    "        elif word.endswith('biliti'):\n",
    "            word = self.replaceM0(word, 'biliti', 'ble')\n",
    "        return word\n",
    "\n",
    "    def step3(self, word):\n",
    "        if word.endswith('icate'):\n",
    "            word = self.replaceM0(word, 'icate', 'ic')\n",
    "        elif word.endswith('ative'):\n",
    "            word = self.replaceM0(word, 'ative', '')\n",
    "        elif word.endswith('alize'):\n",
    "            word = self.replaceM0(word, 'alize', 'al')\n",
    "        elif word.endswith('iciti'):\n",
    "            word = self.replaceM0(word, 'iciti', 'ic')\n",
    "        elif word.endswith('ful'):\n",
    "            word = self.replaceM0(word, 'ful', '')\n",
    "        elif word.endswith('ness'):\n",
    "            word = self.replaceM0(word, 'ness', '')\n",
    "        return word\n",
    "\n",
    "    def step4(self, word):\n",
    "        if word.endswith('al'):\n",
    "            word = self.replaceM1(word, 'al', '')\n",
    "        elif word.endswith('ance'):\n",
    "            word = self.replaceM1(word, 'ance', '')\n",
    "        elif word.endswith('ence'):\n",
    "            word = self.replaceM1(word, 'ence', '')\n",
    "        elif word.endswith('er'):\n",
    "            word = self.replaceM1(word, 'er', '')\n",
    "        elif word.endswith('ic'):\n",
    "            word = self.replaceM1(word, 'ic', '')\n",
    "        elif word.endswith('able'):\n",
    "            word = self.replaceM1(word, 'able', '')\n",
    "        elif word.endswith('ible'):\n",
    "            word = self.replaceM1(word, 'ible', '')\n",
    "        elif word.endswith('ant'):\n",
    "            word = self.replaceM1(word, 'ant', '')\n",
    "        elif word.endswith('ement'):\n",
    "            word = self.replaceM1(word, 'ement', '')\n",
    "        elif word.endswith('ment'):\n",
    "            word = self.replaceM1(word, 'ment', '')\n",
    "        elif word.endswith('ent'):\n",
    "            word = self.replaceM1(word, 'ent', '')\n",
    "        elif word.endswith('ou'):\n",
    "            word = self.replaceM1(word, 'ou', '')\n",
    "        elif word.endswith('ism'):\n",
    "            word = self.replaceM1(word, 'ism', '')\n",
    "        elif word.endswith('ate'):\n",
    "            word = self.replaceM1(word, 'ate', '')\n",
    "        elif word.endswith('iti'):\n",
    "            word = self.replaceM1(word, 'iti', '')\n",
    "        elif word.endswith('ous'):\n",
    "            word = self.replaceM1(word, 'ous', '')\n",
    "        elif word.endswith('ive'):\n",
    "            word = self.replaceM1(word, 'ive', '')\n",
    "        elif word.endswith('ize'):\n",
    "            word = self.replaceM1(word, 'ize', '')\n",
    "        elif word.endswith('ion'):\n",
    "            result = word.rfind('ion')\n",
    "            base = word[:result]\n",
    "            if self.getM(base) > 1 and (self.endsWith(base, 's') or self.endsWith(base, 't')):\n",
    "                word = base\n",
    "            word = self.replaceM1(word, '', '')\n",
    "        return word\n",
    "\n",
    "    def step5a(self, word):\n",
    "        if word.endswith('e'):\n",
    "            base = word[:-1]\n",
    "            if self.getM(base) > 1:\n",
    "                word = base\n",
    "            elif self.getM(base) == 1 and not self.cvc(base):\n",
    "                word = base\n",
    "        return word\n",
    "\n",
    "    def step5b(self, word):\n",
    "        if self.getM(word) > 1 and self.doubleCons(word) and self.endsWith(word, 'l'):\n",
    "            word = word[:-1]\n",
    "        return word\n",
    "\n",
    "    def stem(self, word):\n",
    "        word = self.step1a(word)\n",
    "        word = self.step1b(word)\n",
    "        word = self.step1c(word)\n",
    "        word = self.step2(word)\n",
    "        word = self.step3(word)\n",
    "        word = self.step4(word)\n",
    "        word = self.step5a(word)\n",
    "        word = self.step5b(word)\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemArray(words):\n",
    "    psc = PorterStemmerCustom()\n",
    "    result = []\n",
    "    for w in words:\n",
    "        result.append(psc.stem(w))\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWordsHandler:\n",
    "    #https://stackoverflow.com/questions/6022764/python-removing-list-element-while-iterating-over-list/6024599\n",
    "    #https://gist.github.com/sebleier/554280\n",
    "    def isStopWord(self,word):\n",
    "        stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "        if word in stop_words:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def removeStopWords(self,words):\n",
    "        for i in list(words):\n",
    "            if self.isStopWord(i) or i == '':\n",
    "                words.remove(i)\n",
    "            else:\n",
    "                pass\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCorpusData(path):\n",
    "    files = []\n",
    "    read_tuples = []\n",
    "    #Lendo arquivos da pasta data/\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            #Caso seja .xls, eh o excel que possui os as respostas para o treinamento\n",
    "            if '.xls' in file:\n",
    "                xls = pd.ExcelFile(f'{path}{file}')\n",
    "                #Transformar em DataFrame\n",
    "                df = xls.parse('File list')\n",
    "            elif '.txt' in file:\n",
    "                with open(f'{path}{file}', 'r', encoding=\"utf8\", errors='ignore') as j:\n",
    "                    #Montar um lista de tuplas para mapear arquivo e conteudos\n",
    "                    read_tuples.append((file, j.read()))\n",
    "\n",
    "    #Transformar lista de tuplas em DF\n",
    "    df_tuples = pd.DataFrame(read_tuples, columns=['File', 'Content'])\n",
    "    #Realizar o Join entre os arquivos para mapear conteudo e respostas de treinamento\n",
    "    return pd.merge(df_tuples, df, how='left', left_on = 'File', right_on = 'File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>non</td>\n",
       "      <td>Inheritance is a basic concept of Object-Orien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>cut</td>\n",
       "      <td>PageRank is a link analysis algorithm used by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>light</td>\n",
       "      <td>The vector space model (also called, term vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>heavy</td>\n",
       "      <td>Bayes’ theorem was names after Rev Thomas Baye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>non</td>\n",
       "      <td>Dynamic Programming is an algorithm design tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Category                                            Content\n",
       "0  g0pA_taska.txt      non  Inheritance is a basic concept of Object-Orien...\n",
       "1  g0pA_taskb.txt      cut  PageRank is a link analysis algorithm used by ...\n",
       "2  g0pA_taskc.txt    light  The vector space model (also called, term vect...\n",
       "3  g0pA_taskd.txt    heavy  Bayes’ theorem was names after Rev Thomas Baye...\n",
       "4  g0pA_taske.txt      non  Dynamic Programming is an algorithm design tec..."
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/'\n",
    "corpusDF = readCorpusData(path)\n",
    "corpusDF = corpusDF[['File', 'Category','Content']]\n",
    "corpusDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>g3pC_taskd.txt</td>\n",
       "      <td>non</td>\n",
       "      <td>Inheritance allows programs developed in an Ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  File Category  \\\n",
       "count              100       95   \n",
       "unique             100        4   \n",
       "top     g3pC_taskd.txt      non   \n",
       "freq                 1       38   \n",
       "\n",
       "                                                  Content  \n",
       "count                                                 100  \n",
       "unique                                                100  \n",
       "top     Inheritance allows programs developed in an Ob...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "taska = corpusDF[corpusDF.File.str.contains('taska.txt')].fillna(0)\n",
    "taskb = corpusDF[corpusDF.File.str.contains('taskb.txt')].fillna(0)\n",
    "taskc = corpusDF[corpusDF.File.str.contains('taskc.txt')].fillna(0)\n",
    "taskd = corpusDF[corpusDF.File.str.contains('taskd.txt')].fillna(0)\n",
    "taske = corpusDF[corpusDF.File.str.contains('taske.txt')].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCount(words):\n",
    "    count= nltk.defaultdict(int)\n",
    "    for word in words:\n",
    "        count[word] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist(v1, v2):\n",
    "    import numpy as np\n",
    "    product = np.dot(v1,v2)\n",
    "    \n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    \n",
    "    return product/(norm_v2*norm_v1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSim(t1, t2):\n",
    "    import numpy as np\n",
    "    vocabulary = []\n",
    "    \n",
    "    for key in t1:\n",
    "        vocabulary.append(key)\n",
    "    for key in t2:\n",
    "        vocabulary.append(key)\n",
    "    \n",
    "    vocabulary_size = len(vocabulary)\n",
    "    \n",
    "    d1 = np.zeros(vocabulary_size, dtype=np.int)\n",
    "    d2 = np.zeros(vocabulary_size, dtype=np.int)\n",
    "    \n",
    "    i = 0\n",
    "    for (k) in vocabulary:\n",
    "        d1[i] = t1.get(k, 0)\n",
    "        d2[i] = t2.get(k, 0)\n",
    "        i += 1\n",
    "\n",
    "    return cos_dist(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createF1(task):\n",
    "    task['Tokens'] = task['Content'].map(tokenizer).map(normalizer)\n",
    "    task['WCount'] = task['Tokens'].map(wordCount)\n",
    "    task['f1'] = task.WCount.map(lambda t: getSim(task.WCount.iloc[-1], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createF2(task):\n",
    "    task['Tokens'] = task['Content'].map(tokenizer).map(normalizer)\n",
    "    swh = StopWordsHandler()\n",
    "    task['StopWordsOut'] = task['Tokens'].map(swh.removeStopWords)\n",
    "    task['WCount'] = task['StopWordsOut'].map(wordCount)\n",
    "    task['f2'] = task.WCount.map(lambda t: getSim(task.WCount.iloc[-1], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createF3(task):\n",
    "    ps = PorterStemmerCustom()\n",
    "    task['Tokens'] = task['Content'].map(tokenizer).map(normalizer)\n",
    "    swh = StopWordsHandler()\n",
    "    task['StopWordsOut'] = task['Tokens'].map(swh.removeStopWords)\n",
    "    task['Stem'] = task['StopWordsOut'].map(stemArray)\n",
    "    task['WCount'] = task['Stem'].map(wordCount)\n",
    "    task['f3'] = task.WCount.map(lambda t: getSim(task.WCount.iloc[-1], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createF4(task):\n",
    "    ps = PorterStemmerCustom()\n",
    "    task['Tokens'] = task['Content'].map(tokenizer).map(normalizer)\n",
    "    swh = StopWordsHandler()\n",
    "    task['StopWordsOut'] = task['Tokens'].map(swh.removeStopWords)\n",
    "    task['Lem'] = task['StopWordsOut'].map(lemmatizer)\n",
    "    task['WCount'] = task['Lem'].map(wordCount)\n",
    "    task['f4'] = task.WCount.map(lambda t: getSim(task.WCount.iloc[-1], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "corpusDF = readCorpusData(path)\n",
    "corpusDF = corpusDF[['File', 'Category','Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "taska = corpusDF[corpusDF.File.str.contains('taska.txt')].fillna(0)\n",
    "taskb = corpusDF[corpusDF.File.str.contains('taskb.txt')].fillna(0)\n",
    "taskc = corpusDF[corpusDF.File.str.contains('taskc.txt')].fillna(0)\n",
    "taskd = corpusDF[corpusDF.File.str.contains('taskd.txt')].fillna(0)\n",
    "taske = corpusDF[corpusDF.File.str.contains('taske.txt')].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "createF1(taska)\n",
    "createF1(taskb)\n",
    "createF1(taskc)\n",
    "createF1(taskd)\n",
    "createF1(taske)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "createF2(taska)\n",
    "createF2(taskb)\n",
    "createF2(taskc)\n",
    "createF2(taskd)\n",
    "createF2(taske)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "createF3(taska)\n",
    "createF3(taskb)\n",
    "createF3(taskc)\n",
    "createF3(taskd)\n",
    "createF3(taske)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "createF4(taska)\n",
    "createF4(taskb)\n",
    "createF4(taskc)\n",
    "createF4(taskd)\n",
    "createF4(taske)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "taska.drop(taska.index[-1], inplace=True)\n",
    "taskb.drop(taskb.index[-1], inplace=True)\n",
    "taskc.drop(taskc.index[-1], inplace=True)\n",
    "taskd.drop(taskd.index[-1], inplace=True)\n",
    "taske.drop(taske.index[-1], inplace=True)\n",
    "\n",
    "frames = [taska, taskb, taskc, taskd, taske]\n",
    "\n",
    "df = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Category</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>non</td>\n",
       "      <td>0.645986</td>\n",
       "      <td>0.439486</td>\n",
       "      <td>0.509229</td>\n",
       "      <td>0.495879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>non</td>\n",
       "      <td>0.658039</td>\n",
       "      <td>0.186013</td>\n",
       "      <td>0.536226</td>\n",
       "      <td>0.467069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g0pC_taska.txt</td>\n",
       "      <td>heavy</td>\n",
       "      <td>0.838993</td>\n",
       "      <td>0.727802</td>\n",
       "      <td>0.775872</td>\n",
       "      <td>0.755284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>g0pD_taska.txt</td>\n",
       "      <td>cut</td>\n",
       "      <td>0.938483</td>\n",
       "      <td>0.876625</td>\n",
       "      <td>0.902144</td>\n",
       "      <td>0.885649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>g0pE_taska.txt</td>\n",
       "      <td>light</td>\n",
       "      <td>0.993699</td>\n",
       "      <td>0.985442</td>\n",
       "      <td>0.988046</td>\n",
       "      <td>0.987032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Category        f1        f2        f3        f4\n",
       "0   g0pA_taska.txt      non  0.645986  0.439486  0.509229  0.495879\n",
       "5   g0pB_taska.txt      non  0.658039  0.186013  0.536226  0.467069\n",
       "10  g0pC_taska.txt    heavy  0.838993  0.727802  0.775872  0.755284\n",
       "15  g0pD_taska.txt      cut  0.938483  0.876625  0.902144  0.885649\n",
       "20  g0pE_taska.txt    light  0.993699  0.985442  0.988046  0.987032"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Content', 'Tokens', 'WCount', 'StopWordsOut', 'Stem', 'Lem'])\n",
    "df.head()\n",
    "#f1 - Apenas tokenizacao\n",
    "#f2 - Tokenizacao + StopWords Removal\n",
    "#f3 - Tokenizacao + StopWords Removal + Stemming\n",
    "#f4 - Tokenizacao + StopWords Removal + Segmentacao + Lemmatizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.829516</td>\n",
       "      <td>0.677044</td>\n",
       "      <td>0.733911</td>\n",
       "      <td>0.723926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.104126</td>\n",
       "      <td>0.195469</td>\n",
       "      <td>0.157721</td>\n",
       "      <td>0.164721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.504559</td>\n",
       "      <td>0.173395</td>\n",
       "      <td>0.337205</td>\n",
       "      <td>0.273117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.784752</td>\n",
       "      <td>0.552883</td>\n",
       "      <td>0.625465</td>\n",
       "      <td>0.605653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.838993</td>\n",
       "      <td>0.673948</td>\n",
       "      <td>0.728831</td>\n",
       "      <td>0.719417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.904170</td>\n",
       "      <td>0.832255</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.857819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999229</td>\n",
       "      <td>0.997983</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>0.998337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1         f2         f3         f4\n",
       "count  95.000000  95.000000  95.000000  95.000000\n",
       "mean    0.829516   0.677044   0.733911   0.723926\n",
       "std     0.104126   0.195469   0.157721   0.164721\n",
       "min     0.504559   0.173395   0.337205   0.273117\n",
       "25%     0.784752   0.552883   0.625465   0.605653\n",
       "50%     0.838993   0.673948   0.728831   0.719417\n",
       "75%     0.904170   0.832255   0.860007   0.857819\n",
       "max     0.999229   0.997983   0.998351   0.998337"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1edc380a668>"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('Category')['f1'].nunique().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "features = ['f1', 'f2', 'f3', 'f4']\n",
    "target = ['Category']\n",
    "def NBProcess(df, target, features):\n",
    "    #X features que utilizaremos para treinar o modelo\n",
    "    X = df[features] \n",
    "\n",
    "    #Y variável resposta, no caso nível de plágio\n",
    "    y = df[target]\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2) \n",
    "\n",
    "    gauss = GaussianNB()\n",
    "\n",
    "    gauss.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gauss.predict(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print('Matriz de confusão:')\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print()\n",
    "    print(f'Acurácia da classificação: {accuracy*100}%')\n",
    "    print('Resumo da classificação:')\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão:\n",
      "[[0 3 1 1]\n",
      " [0 3 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 1 8]]\n",
      "\n",
      "Acurácia da classificação: 57.89473684210527%\n",
      "Resumo da classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cut       0.00      0.00      0.00         5\n",
      "       heavy       0.50      0.60      0.55         5\n",
      "       light       0.00      0.00      0.00         0\n",
      "         non       0.80      0.89      0.84         9\n",
      "\n",
      "    accuracy                           0.58        19\n",
      "   macro avg       0.33      0.37      0.35        19\n",
      "weighted avg       0.51      0.58      0.54        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\renan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\renan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "NBProcess(df, target, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuff = df.sample(frac=1, random_state=2)\n",
    "\n",
    "non_df = df_shuff.loc[df_shuff['Category'] == 'non']\n",
    "df_shuff = df_shuff[df_shuff['Category'] != 'non']\n",
    "\n",
    "non_df = non_df.sample(n=19, random_state=5)\n",
    "\n",
    "balanced_df = pd.concat([non_df, df_shuff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1edc31eff28>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "balanced_df.groupby('Category')['f1'].nunique().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão:\n",
      "[[0 1 0 1]\n",
      " [4 3 0 0]\n",
      " [2 2 0 1]\n",
      " [0 1 0 1]]\n",
      "\n",
      "Acurácia da classificação: 25.0%\n",
      "Resumo da classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cut       0.00      0.00      0.00         2\n",
      "       heavy       0.43      0.43      0.43         7\n",
      "       light       0.00      0.00      0.00         5\n",
      "         non       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.19      0.23      0.21        16\n",
      "weighted avg       0.23      0.25      0.24        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\renan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "NBProcess(balanced_df, target, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

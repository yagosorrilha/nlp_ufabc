{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_segmentation (string):\n",
    "    segmented_string = nltk.sent_tokenize(string)\n",
    "    return segmented_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_without_punct(string):\n",
    "    regex_punctuation = r'[^\\w\\s]'\n",
    "    string_without_punct = re.sub(regex_punctuation,'',string)\n",
    "    return string_without_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.VERB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(string_without_punct):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    \n",
    "    for w in tokenizer(string_without_punct):\n",
    "        lemmas.append(lemmatizer.lemmatize(w, get_wordnet_pos(w)))\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(string):\n",
    "    #https://www.w3schools.com/python/python_regex.asp#findall\n",
    "    regex = r\"\\b[-a-zA-ZÀ-ÖØ-öø-ÿ0-9]+\\b\"\n",
    "    return re.findall(regex, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(word):\n",
    "    return [ w.lower() for w in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PorterStemmerCustom:\n",
    "    #https://tartarus.org/martin/PorterStemmer/python.txt\n",
    "    def isCons(self, letter):\n",
    "        if letter == 'a' or letter == 'e' or letter == 'i' or letter == 'o' or letter == 'u':\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def isConsonant(self, word, i):\n",
    "        letter = word[i]\n",
    "        if self.isCons(letter):\n",
    "            if letter == 'y' and self.isCons(word[i-1]):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def isVowel(self, word, i):\n",
    "        return not(self.isConsonant(word, i))\n",
    "\n",
    "    # *S\n",
    "    def endsWith(self, stem, letter):\n",
    "        if stem.endswith(letter):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # *v*\n",
    "    def containsVowel(self, stem):\n",
    "        for i in stem:\n",
    "            if not self.isCons(i):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # *d\n",
    "    def doubleCons(self, stem):\n",
    "        if len(stem) >= 2:\n",
    "            if self.isConsonant(stem, -1) and self.isConsonant(stem, -2):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def getForm(self, word):\n",
    "        form = []\n",
    "        formStr = ''\n",
    "        for i in range(len(word)):\n",
    "            if self.isConsonant(word, i):\n",
    "                if i != 0:\n",
    "                    prev = form[-1]\n",
    "                    if prev != 'C':\n",
    "                        form.append('C')\n",
    "                else:\n",
    "                    form.append('C')\n",
    "            else:\n",
    "                if i != 0:\n",
    "                    prev = form[-1]\n",
    "                    if prev != 'V':\n",
    "                        form.append('V')\n",
    "                else:\n",
    "                    form.append('V')\n",
    "        for j in form:\n",
    "            formStr += j\n",
    "        return formStr\n",
    "\n",
    "    def getM(self, word):\n",
    "        form = self.getForm(word)\n",
    "        m = form.count('VC')\n",
    "        return m\n",
    "\n",
    "    # *o\n",
    "    def cvc(self, word):\n",
    "        if len(word) >= 3:\n",
    "            f = -3\n",
    "            s = -2\n",
    "            t = -1\n",
    "            third = word[t]\n",
    "            if self.isConsonant(word, f) and self.isVowel(word, s) and self.isConsonant(word, t):\n",
    "                if third != 'w' and third != 'x' and third != 'y':\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def replace(self, orig, rem, rep):\n",
    "        result = orig.rfind(rem)\n",
    "        base = orig[:result]\n",
    "        replaced = base + rep\n",
    "        return replaced\n",
    "\n",
    "    def replaceM0(self, orig, rem, rep):\n",
    "        result = orig.rfind(rem)\n",
    "        base = orig[:result]\n",
    "        if self.getM(base) > 0:\n",
    "            replaced = base + rep\n",
    "            return replaced\n",
    "        else:\n",
    "            return orig\n",
    "\n",
    "    def replaceM1(self, orig, rem, rep):\n",
    "        result = orig.rfind(rem)\n",
    "        base = orig[:result]\n",
    "        if self.getM(base) > 1:\n",
    "            replaced = base + rep\n",
    "            return replaced\n",
    "        else:\n",
    "            return orig\n",
    "\n",
    "    def step1a(self, word):\n",
    "        if word.endswith('sses'):\n",
    "            word = self.replace(word, 'sses', 'ss')\n",
    "        elif word.endswith('ies'):\n",
    "            word = self.replace(word, 'ies', 'i')\n",
    "        elif word.endswith('ss'):\n",
    "            word = self.replace(word, 'ss', 'ss')\n",
    "        elif word.endswith('s'):\n",
    "            word = self.replace(word, 's', '')\n",
    "        else:\n",
    "            pass\n",
    "        return word\n",
    "\n",
    "    def step1b(self, word):\n",
    "        flag = False\n",
    "        if word.endswith('eed'):\n",
    "            result = word.rfind('eed')\n",
    "            base = word[:result]\n",
    "            if self.getM(base) > 0:\n",
    "                word = base\n",
    "                word += 'ee'\n",
    "        elif word.endswith('ed'):\n",
    "            result = word.rfind('ed')\n",
    "            base = word[:result]\n",
    "            if self.containsVowel(base):\n",
    "                word = base\n",
    "                flag = True\n",
    "        elif word.endswith('ing'):\n",
    "            result = word.rfind('ing')\n",
    "            base = word[:result]\n",
    "            if self.containsVowel(base):\n",
    "                word = base\n",
    "                flag = True\n",
    "        if flag:\n",
    "            if word.endswith('at') or word.endswith('bl') or word.endswith('iz'):\n",
    "                word += 'e'\n",
    "            elif self.doubleCons(word) and not self.endsWith(word, 'l') and not self.endsWith(word, 's') and not self.endsWith(word, 'z'):\n",
    "                word = word[:-1]\n",
    "            elif self.getM(word) == 1 and self.cvc(word):\n",
    "                word += 'e'\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        return word\n",
    "\n",
    "    def step1c(self, word):\n",
    "        if word.endswith('y'):\n",
    "            result = word.rfind('y')\n",
    "            base = word[:result]\n",
    "            if self.containsVowel(base):\n",
    "                word = base\n",
    "                word += 'i'\n",
    "        return word\n",
    "\n",
    "    def step2(self, word):\n",
    "        if word.endswith('ational'):\n",
    "            word = self.replaceM0(word, 'ational', 'ate')\n",
    "        elif word.endswith('tional'):\n",
    "            word = self.replaceM0(word, 'tional', 'tion')\n",
    "        elif word.endswith('enci'):\n",
    "            word = self.replaceM0(word, 'enci', 'ence')\n",
    "        elif word.endswith('anci'):\n",
    "            word = self.replaceM0(word, 'anci', 'ance')\n",
    "        elif word.endswith('izer'):\n",
    "            word = self.replaceM0(word, 'izer', 'ize')\n",
    "        elif word.endswith('abli'):\n",
    "            word = self.replaceM0(word, 'abli', 'able')\n",
    "        elif word.endswith('alli'):\n",
    "            word = self.replaceM0(word, 'alli', 'al')\n",
    "        elif word.endswith('entli'):\n",
    "            word = self.replaceM0(word, 'entli', 'ent')\n",
    "        elif word.endswith('eli'):\n",
    "            word = self.replaceM0(word, 'eli', 'e')\n",
    "        elif word.endswith('ousli'):\n",
    "            word = self.replaceM0(word, 'ousli', 'ous')\n",
    "        elif word.endswith('ization'):\n",
    "            word = self.replaceM0(word, 'ization', 'ize')\n",
    "        elif word.endswith('ation'):\n",
    "            word = self.replaceM0(word, 'ation', 'ate')\n",
    "        elif word.endswith('ator'):\n",
    "            word = self.replaceM0(word, 'ator', 'ate')\n",
    "        elif word.endswith('alism'):\n",
    "            word = self.replaceM0(word, 'alism', 'al')\n",
    "        elif word.endswith('iveness'):\n",
    "            word = self.replaceM0(word, 'iveness', 'ive')\n",
    "        elif word.endswith('fulness'):\n",
    "            word = self.replaceM0(word, 'fulness', 'ful')\n",
    "        elif word.endswith('ousness'):\n",
    "            word = self.replaceM0(word, 'ousness', 'ous')\n",
    "        elif word.endswith('aliti'):\n",
    "            word = self.replaceM0(word, 'aliti', 'al')\n",
    "        elif word.endswith('iviti'):\n",
    "            word = self.replaceM0(word, 'iviti', 'ive')\n",
    "        elif word.endswith('biliti'):\n",
    "            word = self.replaceM0(word, 'biliti', 'ble')\n",
    "        return word\n",
    "\n",
    "    def step3(self, word):\n",
    "        if word.endswith('icate'):\n",
    "            word = self.replaceM0(word, 'icate', 'ic')\n",
    "        elif word.endswith('ative'):\n",
    "            word = self.replaceM0(word, 'ative', '')\n",
    "        elif word.endswith('alize'):\n",
    "            word = self.replaceM0(word, 'alize', 'al')\n",
    "        elif word.endswith('iciti'):\n",
    "            word = self.replaceM0(word, 'iciti', 'ic')\n",
    "        elif word.endswith('ful'):\n",
    "            word = self.replaceM0(word, 'ful', '')\n",
    "        elif word.endswith('ness'):\n",
    "            word = self.replaceM0(word, 'ness', '')\n",
    "        return word\n",
    "\n",
    "    def step4(self, word):\n",
    "        if word.endswith('al'):\n",
    "            word = self.replaceM1(word, 'al', '')\n",
    "        elif word.endswith('ance'):\n",
    "            word = self.replaceM1(word, 'ance', '')\n",
    "        elif word.endswith('ence'):\n",
    "            word = self.replaceM1(word, 'ence', '')\n",
    "        elif word.endswith('er'):\n",
    "            word = self.replaceM1(word, 'er', '')\n",
    "        elif word.endswith('ic'):\n",
    "            word = self.replaceM1(word, 'ic', '')\n",
    "        elif word.endswith('able'):\n",
    "            word = self.replaceM1(word, 'able', '')\n",
    "        elif word.endswith('ible'):\n",
    "            word = self.replaceM1(word, 'ible', '')\n",
    "        elif word.endswith('ant'):\n",
    "            word = self.replaceM1(word, 'ant', '')\n",
    "        elif word.endswith('ement'):\n",
    "            word = self.replaceM1(word, 'ement', '')\n",
    "        elif word.endswith('ment'):\n",
    "            word = self.replaceM1(word, 'ment', '')\n",
    "        elif word.endswith('ent'):\n",
    "            word = self.replaceM1(word, 'ent', '')\n",
    "        elif word.endswith('ou'):\n",
    "            word = self.replaceM1(word, 'ou', '')\n",
    "        elif word.endswith('ism'):\n",
    "            word = self.replaceM1(word, 'ism', '')\n",
    "        elif word.endswith('ate'):\n",
    "            word = self.replaceM1(word, 'ate', '')\n",
    "        elif word.endswith('iti'):\n",
    "            word = self.replaceM1(word, 'iti', '')\n",
    "        elif word.endswith('ous'):\n",
    "            word = self.replaceM1(word, 'ous', '')\n",
    "        elif word.endswith('ive'):\n",
    "            word = self.replaceM1(word, 'ive', '')\n",
    "        elif word.endswith('ize'):\n",
    "            word = self.replaceM1(word, 'ize', '')\n",
    "        elif word.endswith('ion'):\n",
    "            result = word.rfind('ion')\n",
    "            base = word[:result]\n",
    "            if self.getM(base) > 1 and (self.endsWith(base, 's') or self.endsWith(base, 't')):\n",
    "                word = base\n",
    "            word = self.replaceM1(word, '', '')\n",
    "        return word\n",
    "\n",
    "    def step5a(self, word):\n",
    "        if word.endswith('e'):\n",
    "            base = word[:-1]\n",
    "            if self.getM(base) > 1:\n",
    "                word = base\n",
    "            elif self.getM(base) == 1 and not self.cvc(base):\n",
    "                word = base\n",
    "        return word\n",
    "\n",
    "    def step5b(self, word):\n",
    "        if self.getM(word) > 1 and self.doubleCons(word) and self.endsWith(word, 'l'):\n",
    "            word = word[:-1]\n",
    "        return word\n",
    "\n",
    "    def stem(self, word):\n",
    "        word = self.step1a(word)\n",
    "        word = self.step1b(word)\n",
    "        word = self.step1c(word)\n",
    "        word = self.step2(word)\n",
    "        word = self.step3(word)\n",
    "        word = self.step4(word)\n",
    "        word = self.step5a(word)\n",
    "        word = self.step5b(word)\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWordsHandler:\n",
    "    #https://stackoverflow.com/questions/6022764/python-removing-list-element-while-iterating-over-list/6024599\n",
    "    #https://gist.github.com/sebleier/554280\n",
    "    def isStopWord(self,word):\n",
    "        stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "        if word in stop_words:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def removeStopWords(self,words):\n",
    "        for i in list(words):\n",
    "            if self.isStopWord(i) or i == '':\n",
    "                words.remove(i)\n",
    "            else:\n",
    "                pass\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCorpusData(path):\n",
    "    files = []\n",
    "    read_tuples = []\n",
    "    #Lendo arquivos da pasta data/\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            #Caso seja .xls, eh o excel que possui os as respostas para o treinamento\n",
    "            if '.xls' in file:\n",
    "                xls = pd.ExcelFile(f'{path}{file}')\n",
    "                #Transformar em DataFrame\n",
    "                df = xls.parse('File list')\n",
    "            elif '.txt' in file:\n",
    "                with open(f'{path}{file}', 'r', encoding=\"utf8\", errors='ignore') as j:\n",
    "                    #Montar um lista de tuplas para mapear arquivo e conteudos\n",
    "                    read_tuples.append((file, j.read()))\n",
    "\n",
    "    #Transformar lista de tuplas em DF\n",
    "    df_tuples = pd.DataFrame(read_tuples, columns=['File', 'Content'])\n",
    "    #Realizar o Join entre os arquivos para mapear conteudo e respostas de treinamento\n",
    "    return pd.merge(df_tuples, df, how='left', left_on = 'File', right_on = 'File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "corpusDF = readCorpusData(path)\n",
    "corpusDF = corpusDF[['File', 'Category','Content']]\n",
    "corpusDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taska = corpusDF[corpusDF.File.str.contains('taska.txt')].fillna(0)\n",
    "taskb = corpusDF[corpusDF.File.str.contains('taskb.txt')].fillna(0)\n",
    "taskc = corpusDF[corpusDF.File.str.contains('taskc.txt')].fillna(0)\n",
    "taskd = corpusDF[corpusDF.File.str.contains('taskd.txt')].fillna(0)\n",
    "taske = corpusDF[corpusDF.File.str.contains('taske.txt')].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taske['Tokens'] = taske['Content'].map(tokenizer).map(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCount(words):\n",
    "    count= nltk.defaultdict(int)\n",
    "    for word in words:\n",
    "        count[word] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist(v1, v2):\n",
    "    import numpy as np\n",
    "    product = np.dot(v1,v2)\n",
    "    \n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    \n",
    "    return product/(norm_v2*norm_v1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSim(t1, t2):\n",
    "    import numpy as np\n",
    "    vocabulary = []\n",
    "    \n",
    "    for key in t1:\n",
    "        vocabulary.append(key)\n",
    "    for key in t2:\n",
    "        vocabulary.append(key)\n",
    "    \n",
    "    vocabulary_size = len(vocabulary)\n",
    "    \n",
    "    d1 = np.zeros(vocabulary_size, dtype=np.int)\n",
    "    d2 = np.zeros(vocabulary_size, dtype=np.int)\n",
    "    \n",
    "    i = 0\n",
    "    for (k) in vocabulary:\n",
    "        d1[i] = t1.get(k, 0)\n",
    "        d2[i] = t2.get(k, 0)\n",
    "        i += 1\n",
    "\n",
    "    return cos_dist(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taske['WCount'] = taske['Tokens'].map(wordCount)\n",
    "taske[['File','Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSim(taske.WCount.iloc[-1], taske.WCount.iloc[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "#X nossos dados\n",
    "X = \n",
    "\n",
    "#Y variável resposta, no caso nível de plágio\n",
    "Y = \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) \n",
    "\n",
    "gauss = GaussianNB()\n",
    "\n",
    "gauss.fit(X_Train, y_train)\n",
    "\n",
    "y_pred = gauss.predict(X_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia do classificador Naive Bayes: {(accuracy*100)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
